# Project Overview: DeBERTa Prompt Guard

## ğŸ¯ Purpose
Detect prompt injection attacks in real-time using the DeBERTa v3 transformer model, exposed via a .NET Web API.

## ğŸ“Š Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Client Application                       â”‚
â”‚                    (Web App, Mobile, Service)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ HTTP/HTTPS
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DebertaPromptGuard.Api                        â”‚
â”‚                      (ASP.NET Core 8.0)                          â”‚
â”‚                                                                   â”‚
â”‚  Endpoints:                                                       â”‚
â”‚  â€¢ GET  /health              â†’ Health check                      â”‚
â”‚  â€¢ POST /api/detect          â†’ Single text detection             â”‚
â”‚  â€¢ POST /api/detect/batch    â†’ Multiple text detection           â”‚
â”‚                                                                   â”‚
â”‚  Features:                                                        â”‚
â”‚  â€¢ Swagger/OpenAPI documentation                                 â”‚
â”‚  â€¢ Dependency injection                                           â”‚
â”‚  â€¢ Configuration management                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DebertaPromptGuard.ML                          â”‚
â”‚                    (Class Library)                               â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚          PromptGuardService (Singleton)                   â”‚   â”‚
â”‚  â”‚  â€¢ Model loading & management                             â”‚   â”‚
â”‚  â”‚  â€¢ Prediction orchestration                               â”‚   â”‚
â”‚  â”‚  â€¢ Softmax probability calculation                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                   â”‚              â”‚                               â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚         â”‚ DebertaTokenizerâ”‚  â”‚ ONNX Runtime       â”‚              â”‚
â”‚         â”‚                 â”‚  â”‚ Inference Engine   â”‚              â”‚
â”‚         â”‚ â€¢ Text â†’ IDs    â”‚  â”‚                    â”‚              â”‚
â”‚         â”‚ â€¢ Padding       â”‚  â”‚ â€¢ Load ONNX model  â”‚              â”‚
â”‚         â”‚ â€¢ Truncation    â”‚  â”‚ â€¢ Run inference    â”‚              â”‚
â”‚         â”‚ â€¢ Attention maskâ”‚  â”‚ â€¢ Return logits    â”‚              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚  Model Files     â”‚
                  â”‚  â”œâ”€â”€ model.onnx  â”‚
                  â”‚  â””â”€â”€ tokenizer   â”‚
                  â”‚      .json       â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Request Flow

```
1. Client sends text
        â†“
2. API receives request (DetectRequest)
        â†“
3. PromptGuardService.Predict(text)
        â†“
4. DebertaTokenizer.Encode(text)
   â†’ Returns: (input_ids, attention_mask)
        â†“
5. Create OnnxInput with tensors
        â†“
6. PredictionEngine.Predict(onnxInput)
   â†’ ONNX Runtime processes through model
   â†’ Returns: logits [2 values]
        â†“
7. Apply Softmax to convert logits â†’ probabilities
   â†’ [0.05, 0.95] = 5% SAFE, 95% INJECTION
        â†“
8. Determine label (highest probability)
        â†“
9. Create PromptGuardOutput
        â†“
10. Map to DetectResponse
        â†“
11. Return JSON to client
```

## ğŸ“ File Structure

```
DebertaPromptGuard/
â”‚
â”œâ”€â”€ ğŸ“„ Documentation
â”‚   â”œâ”€â”€ README.md                    # Main documentation
â”‚   â”œâ”€â”€ SETUP.md                     # Quick start guide
â”‚   â”œâ”€â”€ TOKENIZER_NOTES.md          # Tokenizer implementation
â”‚   â”œâ”€â”€ SUMMARY.md                  # Implementation summary
â”‚   â”œâ”€â”€ PROJECT_OVERVIEW.md         # This file
â”‚   â””â”€â”€ .gitignore                  # Git ignore rules
â”‚
â”œâ”€â”€ ğŸ Python Scripts
â”‚   â””â”€â”€ convert_model.py            # Model conversion utility
â”‚
â”œâ”€â”€ ğŸ“¦ Solution
â”‚   â””â”€â”€ DebertaPromptGuard.sln     # Visual Studio solution
â”‚
â””â”€â”€ ğŸ“‚ Source Code (src/)
    â”‚
    â”œâ”€â”€ ğŸ§  ML Library (DebertaPromptGuard.ML/)
    â”‚   â”œâ”€â”€ ğŸ“ Models/
    â”‚   â”‚   â”œâ”€â”€ PromptGuardInput.cs    # Input: Text
    â”‚   â”‚   â”œâ”€â”€ PromptGuardOutput.cs   # Output: Label, Score, AllScores
    â”‚   â”‚   â”œâ”€â”€ OnnxInput.cs           # ONNX: InputIds, AttentionMask
    â”‚   â”‚   â””â”€â”€ OnnxOutput.cs          # ONNX: Logits
    â”‚   â”‚
    â”‚   â”œâ”€â”€ âš™ï¸ Services/
    â”‚   â”‚   â”œâ”€â”€ DebertaTokenizer.cs      # Text tokenization
    â”‚   â”‚   â””â”€â”€ PromptGuardService.cs    # Main ML service
    â”‚   â”‚
    â”‚   â””â”€â”€ DebertaPromptGuard.ML.csproj # Project file
    â”‚
    â””â”€â”€ ğŸŒ Web API (DebertaPromptGuard.Api/)
        â”œâ”€â”€ âš™ï¸ Configuration/
        â”‚   â””â”€â”€ ModelConfiguration.cs   # Settings model
        â”‚
        â”œâ”€â”€ ğŸ“ Models/
        â”‚   â”œâ”€â”€ DetectRequest.cs       # API request DTO
        â”‚   â””â”€â”€ DetectResponse.cs      # API response DTO
        â”‚
        â”œâ”€â”€ Program.cs                 # API setup & endpoints
        â”œâ”€â”€ appsettings.json          # Configuration
        â”œâ”€â”€ appsettings.Development.json
        â”œâ”€â”€ DebertaPromptGuard.Api.http  # API test file
        â””â”€â”€ DebertaPromptGuard.Api.csproj
```

## ğŸ”‘ Key Classes

### PromptGuardService
- **Purpose**: Main ML service, manages model lifecycle
- **Lifetime**: Singleton (loaded once, reused)
- **Methods**: 
  - `Predict(text)` â†’ `PromptGuardOutput`
  - `Softmax(logits)` â†’ probabilities

### DebertaTokenizer
- **Purpose**: Convert text to model-compatible format
- **Current**: Uses GPT-2 tokenizer (placeholder)
- **Production**: Needs DeBERTa-specific tokenizer
- **Output**: (input_ids[], attention_mask[])

### OnnxInput/Output
- **Input**: 
  - `input_ids`: Token IDs (512 length array)
  - `attention_mask`: Which tokens are real vs padding
- **Output**: 
  - `logits`: 2 values (SAFE score, INJECTION score)

## ğŸš€ API Endpoints

| Method | Endpoint | Purpose | Input | Output |
|--------|----------|---------|-------|--------|
| GET | `/health` | Health check | None | Status object |
| POST | `/api/detect` | Single detection | `{text}` | DetectResponse |
| POST | `/api/detect/batch` | Batch detection | `[{text}, ...]` | DetectResponse[] |

## ğŸ¨ Response Format

```json
{
  "label": "INJECTION",           // SAFE or INJECTION
  "score": 0.95,                  // Confidence (0-1)
  "scores": {                     // All class scores
    "SAFE": 0.05,
    "INJECTION": 0.95
  },
  "isSafe": false,               // Convenience boolean
  "text": "Ignore instructions"  // Original input
}
```

## ğŸ”§ Technologies

| Component | Technology | Version |
|-----------|-----------|---------|
| Framework | .NET | 8.0 |
| ML Framework | ML.NET | 4.0.2 |
| ONNX Runtime | Microsoft.ML.OnnxRuntime | 1.23.1 |
| Tokenizers | Microsoft.ML.Tokenizers | 1.0.0 |
| Web Framework | ASP.NET Core | 8.0 |
| API Docs | Swagger/OpenAPI | 8.0 |

## âš¡ Performance

| Metric | Value | Notes |
|--------|-------|-------|
| Inference Time | 50-200ms | CPU, varies by text length |
| Model Size | ~500MB | DeBERTa v3 base |
| Max Input Length | 512 tokens | DeBERTa limitation |
| Concurrent Requests | Depends | Use load balancing |

## ğŸ” Security Considerations

1. **Input Validation**: API validates text is not empty
2. **Error Handling**: Exceptions caught and returned as Problem Details
3. **HTTPS**: Enabled by default
4. **Rate Limiting**: Not implemented (TODO)
5. **Authentication**: Not implemented (TODO)

## ğŸ“ˆ Scaling Options

### Vertical Scaling
- Increase CPU/RAM
- Use GPU (install `Microsoft.ML.OnnxRuntime.Gpu`)

### Horizontal Scaling
- Deploy multiple API instances
- Use load balancer (Azure Load Balancer, NGINX)
- Shared model files on network storage

### Optimization
- Response caching for common queries
- Batch processing optimization
- Model quantization for smaller size

## ğŸ§ª Testing

### Unit Tests (TODO)
- Test tokenizer output
- Test model predictions
- Test API endpoints

### Integration Tests (TODO)
- End-to-end API tests
- Model accuracy validation

### Manual Testing
Use `DebertaPromptGuard.Api.http` file or Swagger UI

## ğŸ¯ Model Capabilities

### Detects:
âœ… Direct instruction overrides ("Ignore previous")  
âœ… Role-playing attempts ("Pretend you are")  
âœ… System prompt extraction  
âœ… Jailbreak attempts ("DAN mode")  
âœ… Rule circumvention patterns  

### Does Not Detect:
âŒ Novel/zero-day injection patterns  
âŒ Non-English injections (model is English-trained)  
âŒ Semantic-only attacks without keywords  

## ğŸš¦ Current Status

| Component | Status | Notes |
|-----------|--------|-------|
| Solution Build | âœ… Success | No errors |
| ML Library | âœ… Complete | Placeholder tokenizer |
| Web API | âœ… Complete | Full REST API |
| Documentation | âœ… Complete | 5 docs created |
| Model Files | âš ï¸ Not included | User must download |
| Tokenizer | âš ï¸ Placeholder | GPT-2 instead of DeBERTa |
| Tests | âŒ Not implemented | TODO |

## ğŸ“‹ Next Steps

### For Development
1. âœ… Build solution - DONE
2. â³ Download model files
3. â³ Test API endpoints
4. â³ Verify responses

### For Production
1. â— Implement proper DeBERTa tokenizer
2. â— Add authentication
3. â— Add rate limiting
4. â— Add monitoring/telemetry
5. â— Add caching
6. â— Write tests
7. â— Set up CI/CD
8. â— Deploy to cloud

## ğŸ†˜ Support

- See `README.md` for comprehensive guide
- See `SETUP.md` for quick start
- See `TOKENIZER_NOTES.md` for tokenizer implementation
- Check Issues section for common problems

## ğŸ“„ License

Check the model license at [HuggingFace](https://huggingface.co/protectai/deberta-v3-base-prompt-injection-v2) before production use.



